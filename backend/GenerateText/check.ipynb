{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMObject import LLMFactory\n",
    "\n",
    "# Initialize the factory and get the LLM object\n",
    "factory = LLMFactory('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = factory.get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" J'adore programmer.\", response_metadata={'model': 'phi3:3.8b', 'created_at': '2024-09-12T17:09:54.407782879Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2708212760, 'load_duration': 2504302489, 'prompt_eval_count': 27, 'prompt_eval_duration': 26031000, 'eval_count': 7, 'eval_duration': 125489000}, id='run-df4a070a-1c3c-43ca-9da3-254d8a0a39a6-0', usage_metadata={'input_tokens': 27, 'output_tokens': 7, 'total_tokens': 34})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \"payments\" dataset used in a travel agency. Below are the details of the columns for this dataset:\n",
      "The Dataset description: This table tracks payment transactions related to customer bookings. It includes details on payment methods, transaction dates, and payment amounts.\n",
      "- attribute:payment_id attribute name:Payment ID Type:serial Description:Unique identifier for each payment transaction. This is an auto-incrementing integer that serves as the primary key.\n",
      "- attribute:booking_id attribute name:Booking ID Type:integer Description:The identifier linking the payment to a specific booking.\n",
      "- attribute:amount attribute name:Payment Amount Type:numeric(10, 2) Description:The amount paid in the transaction.\n",
      "- attribute:payment_method attribute name:Payment Method Type:varchar(50) Description:The method used for payment, such as credit card, PayPal, or bank transfer.\n",
      "- attribute:transaction_date attribute name:Transaction Date Type:timestamp Description:The date and time when the payment transaction occurred.\n",
      "- attribute:status attribute name:Payment Status Type:varchar(50) Description:The current status of the payment, such as completed, pending, or failed.\n",
      "- attribute:created_at attribute name:Record Created At Type:timestamp Description:Timestamp indicating when the payment record was created.\n",
      "- attribute:updated_at attribute name:Record Updated At Type:timestamp Description:Timestamp indicating the last update to the payment record.\n",
      " [/INST]</s>\n",
      "[INST]Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate 5 items only and generate response in json only.[/INST]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Function to load tables data from a JSON file\n",
    "def load_tables_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        tables = json.load(file)\n",
    "    return tables\n",
    "\n",
    "# Function to extract column details for a given dataset name\n",
    "def get_column_details(tables, dataset_name):\n",
    "    \"\"\"\n",
    "    Extract column details for a given dataset name from the tables JSON data.\n",
    "\n",
    "    Parameters:\n",
    "    tables (list): A list of dictionaries representing datasets and their details.\n",
    "    dataset_name (str): The name of the dataset to extract column details for.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the details of the specified dataset.\n",
    "    \"\"\"\n",
    "    for table in tables:\n",
    "        if table['dataset'] == dataset_name:\n",
    "            return table\n",
    "    return None\n",
    "\n",
    "# Function to generate a detailed prompt for LLM based on column details\n",
    "def generate_llm_prompt(table_details):\n",
    "    \"\"\"\n",
    "    Generate a detailed prompt for the LLM to generate synthetic data based on the table details.\n",
    "\n",
    "    Parameters:\n",
    "    table_details (dict): The details of the table for which to generate the LLM prompt.\n",
    "\n",
    "    Returns:\n",
    "    str: A detailed prompt for the LLM.\n",
    "    \"\"\"\n",
    "    prompt = \"\"\n",
    "    description = table_details[\"description\"]\n",
    "    label = table_details[\"label\"]\n",
    "\n",
    "    for property in table_details['properties']:\n",
    "        prompt += f\"- attribute:{property['name']} attribute name:{property['label']} Type:{property['type']} Description:{property['description']}\\n\"\n",
    "\n",
    "    # prompt += \"\\nPlease generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability.\\n\"\n",
    "\n",
    "    return prompt, description, label\n",
    "\n",
    "# Load the tables data from the JSON file\n",
    "file_path = 'data/cols.json'  # Replace with the path to your JSON file\n",
    "tables = load_tables_from_json(file_path)\n",
    "\n",
    "# Example usage: Generate a prompt for the 'customers' dataset\n",
    "dataset_name = 'payments'  # Replace with the desired dataset name\n",
    "table_details = get_column_details(tables, dataset_name)\n",
    "\n",
    "col_prompt, description, label = generate_llm_prompt(table_details)\n",
    "# print(col_prompt)  # This will display the detailed prompt for the LLM\n",
    "\n",
    "# LangChain integration\n",
    "# llm = OpenAI(model=\"text-davinci-003\")  # Replace with your LLM model configuration\n",
    "items_count = 5\n",
    "format = \"json\"\n",
    "\n",
    "ai_message = '''<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \"{dataset_name}\" dataset used in a travel agency. Below are the details of the columns for this dataset:\n",
    "The Dataset description: {dataset_description}\n",
    "{col_prompt} [/INST]</s>\n",
    "[INST]Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate {items_count} items only and generate response in {format} only.[/INST]'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(ai_message)\n",
    "ll = prompt_template.format(dataset_name=dataset_name, dataset_description=description, col_prompt=col_prompt, items_count=items_count, format=format)\n",
    "\n",
    "# ll = prompt_template.format({\n",
    "#     \"dataset_name\": dataset_name,\n",
    "#     \"dataset_description\":description,\n",
    "#     \"col_prompt\":col_prompt\n",
    "# })\n",
    "\n",
    "print(ll)\n",
    "\n",
    "# # Create a LangChain LLMChain\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# # Execute the LLMChain with the generated prompt\n",
    "# response = llm_chain.run(dataset_description=llm_prompt)\n",
    "# print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "custom_llm = Bedrock(\n",
    "    credentials_profile_name=\"bedrock-admin\",\n",
    "    # provider=\"cohere\",\n",
    "    model_id=\"mistral.mixtral-8x7b-instruct-v0:1\",  # ARN like 'arn:aws:bedrock:...' obtained via provisioning the custom model\n",
    "    model_kwargs={\"temperature\": 0.7, \"top_p\":0.7, \"max_tokens\":400, \"top_k\":50},\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt_template | custom_llm | JsonOutputParser()\n",
    "\n",
    "# mm = chain.invoke(input={\n",
    "#     \"dataset_name\":dataset_name,\n",
    "#     \"dataset_description\":description,\n",
    "#     \"col_prompt\":col_prompt,\n",
    "#     \"items_count\":items_count,\n",
    "#     \"format\":format\n",
    "# })\n",
    "\n",
    "\n",
    "\n",
    "# ll = prompt_template.format(dataset_name=dataset_name, dataset_description=description, col_prompt=col_prompt, items_count=items_count, format=format)\n",
    "\n",
    "# <s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \"customers\" dataset used in a travel agency. Below are the details of the columns for this dataset:\n",
    "#     The Dataset description: This table contains detailed information about the customers who use the travel agency's services. It captures personal details, contact information, and preferences, which help the agency in providing personalized travel experiences.\n",
    "#     - attribute:customer_id attribute name:Customer ID Type:serial Description:Unique identifier for each customer. This is an auto-incrementing integer that serves as the primary key.\n",
    "# - attribute:first_name attribute name:First Name Type:varchar(255) Description:The first name of the customer, used for personalized communication and records.\n",
    "# - attribute:last_name attribute name:Last Name Type:varchar(255) Description:The last name of the customer, helping to identify and distinguish customers.\n",
    "# - attribute:email attribute name:Email Address Type:varchar(255) Description:The primary email address of the customer used for communication, including booking confirmations and promotional offers.\n",
    "# - attribute:phone_number attribute name:Phone Number Type:varchar(20) Description:The customer's contact number, used for urgent communications and verification purposes.\n",
    "# - attribute:date_of_birth attribute name:Date of Birth Type:date Description:The date of birth of the customer, useful for providing age-specific offers and travel insurance.\n",
    "# - attribute:preferences attribute name:Travel Preferences Type:jsonb Description:Customer's travel preferences such as preferred destinations, travel class, and special requirements, aiding in personalized service delivery.\n",
    "# - attribute:created_at attribute name:Record Created At Type:timestamp Description:Timestamp indicating when the customer record was created.\n",
    "# - attribute:updated_at attribute name:Record Updated At Type:timestamp Description:Timestamp indicating the last update to the customer record. [/INST]</s> \n",
    "# [INST] Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate 5 items only and generate response in json only. [/INST]\n",
    "\n",
    "\n",
    "# aws bedrock-runtime invoke-model \\\n",
    "# --model-id mistral.mixtral-8x7b-instruct-v0:1 \\\n",
    "# --body \"{\\\"max_tokens\\\":400,\\\"top_p\\\":0.7,\\\"temperature\\\":0.7,\\\"top_k\\\":50,\\\"prompt\\\":\\\"<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \\\\\\\"customers\\\\\\\" dataset used in a travel agency. Below are the details of the columns for this dataset:\\\\r\\\\n    The Dataset description: This table contains detailed information about the customers who use the travel agency's services. It captures personal details, contact information, and preferences, which help the agency in providing personalized travel experiences.\\\\r\\\\n    - attribute:customer_id attribute name:Customer ID Type:serial Description:Unique identifier for each customer. This is an auto-incrementing integer that serves as the primary key.\\\\r\\\\n- attribute:first_name attribute name:First Name Type:varchar(255) Description:The first name of the customer, used for personalized communication and records.\\\\r\\\\n- attribute:last_name attribute name:Last Name Type:varchar(255) Description:The last name of the customer, helping to identify and distinguish customers.\\\\r\\\\n- attribute:email attribute name:Email Address Type:varchar(255) Description:The primary email address of the customer used for communication, including booking confirmations and promotional offers.\\\\r\\\\n- attribute:phone_number attribute name:Phone Number Type:varchar(20) Description:The customer's contact number, used for urgent communications and verification purposes.\\\\r\\\\n- attribute:date_of_birth attribute name:Date of Birth Type:date Description:The date of birth of the customer, useful for providing age-specific offers and travel insurance.\\\\r\\\\n- attribute:preferences attribute name:Travel Preferences Type:jsonb Description:Customer's travel preferences such as preferred destinations, travel class, and special requirements, aiding in personalized service delivery.\\\\r\\\\n- attribute:created_at attribute name:Record Created At Type:timestamp Description:Timestamp indicating when the customer record was created.\\\\r\\\\n- attribute:updated_at attribute name:Record Updated At Type:timestamp Description:Timestamp indicating the last update to the customer record. [/INST]</s> \\\\n[INST] Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate 5 items only and generate response in json only. [/INST]\\\\n [\\\\n  {\\\\n    \\\\\\\"customer_id\\\\\\\": 1,\\\\n    \\\\\\\"first_name\\\\\\\": \\\\\\\"John\\\\\\\",\\\\n    \\\\\\\"last_name\\\\\\\": \\\\\\\"Doe\\\\\\\",\\\\n    \\\\\\\"email\\\\\\\": \\\\\\\"john.doe@example.com\\\\\\\",\\\\n    \\\\\\\"phone_number\\\\\\\": \\\\\\\"123-456-7890\\\\\\\",\\\\n    \\\\\\\"date_of_birth\\\\\\\": \\\\\\\"1980-01-01\\\\\\\",\\\\n    \\\\\\\"preferences\\\\\\\": '{\\\\\\\"preferred_destinations\\\\\\\": [\\\\\\\"Paris\\\\\\\", \\\\\\\"New York\\\\\\\"],\\\\\\\"travel_class\\\\\\\": \\\\\\\"business\\\\\\\",\\\\\\\"special_requirements\\\\\\\": null}',\\\\n    \\\\\\\"created_at\\\\\\\": \\\\\\\"2021-01-01T12:34:56Z\\\\\\\",\\\\n    \\\\\\\"updated_at\\\\\\\": \\\\\\\"2021-01-01T12:34:56Z\\\\\\\"\\\\n  },\\\\n  {\\\\n    \\\\\\\"customer_id\\\\\\\": 2,\\\\n    \\\\\\\"first_name\\\\\\\": \\\\\\\"Jane\\\\\\\",\\\\n    \\\\\\\"last_name\\\\\\\": \\\\\\\"Smith\\\\\\\",\\\\n    \\\\\\\"email\\\\\\\": \\\\\\\"jane.smith@example.com\\\\\\\",\\\\n    \\\\\\\"phone_number\\\\\\\": \\\\\\\"987-654-3210\\\\\\\",\\\\n    \\\\\\\"date_of_birth\\\\\\\": \\\\\\\"1995-03-15\\\\\\\",\\\\n    \\\\\\\"preferences\\\\\\\": '{\\\\\\\"preferred_destinations\\\\\\\": [\\\\\\\"Tokyo\\\\\\\", \\\\\\\"Rome\\\\\\\"],\\\\\\\"travel_class\\\\\\\": \\\\\\\"economy\\\\\\\",\\\\\\\"special_requirements\\\\\\\": {\\\\\\\"dietary_restrictions\\\\\\\": \\\\\\\"vegetarian\\\\\\\"}}',\\\\n    \\\\\\\"created_at\\\\\\\": \\\\\\\"2021-02-01T09:10:11Z\\\\\\\",\\\\n    \\\\\\\"updated_at\\\\\\\": \\\\\\\"2021-02-01T09:10:11Z\\\\\\\"\\\\n  },\\\"}\" \\\n",
    "# --cli-binary-format raw-in-base64-out \\\n",
    "# --region ap-south-1 \\\n",
    "# invoke-model-output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \"payments\" dataset used in a travel agency. Below are the details of the columns for this dataset:\\nThe Dataset description: This table tracks payment transactions related to customer bookings. It includes details on payment methods, transaction dates, and payment amounts.\\n- attribute:payment_id attribute name:Payment ID Type:serial Description:Unique identifier for each payment transaction. This is an auto-incrementing integer that serves as the primary key.\\n- attribute:booking_id attribute name:Booking ID Type:integer Description:The identifier linking the payment to a specific booking.\\n- attribute:amount attribute name:Payment Amount Type:numeric(10, 2) Description:The amount paid in the transaction.\\n- attribute:payment_method attribute name:Payment Method Type:varchar(50) Description:The method used for payment, such as credit card, PayPal, or bank transfer.\\n- attribute:transaction_date attribute name:Transaction Date Type:timestamp Description:The date and time when the payment transaction occurred.\\n- attribute:status attribute name:Payment Status Type:varchar(50) Description:The current status of the payment, such as completed, pending, or failed.\\n- attribute:created_at attribute name:Record Created At Type:timestamp Description:Timestamp indicating when the payment record was created.\\n- attribute:updated_at attribute name:Record Updated At Type:timestamp Description:Timestamp indicating the last update to the payment record.\\n [/INST]</s>\\n[INST]Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate 5 items only and generate response in json only.[/INST]'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = {\n",
    "    \"dataset_name\":dataset_name,\n",
    "    \"dataset_description\":description,\n",
    "    \"col_prompt\":col_prompt,\n",
    "    \"items_count\":items_count,\n",
    "    \"format\":format\n",
    "}\n",
    "\n",
    "# type(prompt_template.format(**p))\n",
    "ai_message.format(**p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "import boto3.session\n",
    "from botocore.exceptions import ClientError\n",
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "import functools\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "class BaseErrorCodes(Enum):\n",
    "    AWS_SESSION_FAILED = (100, \"AWSSessionFailed\", \"AWS Session creation failed\")\n",
    "    GENAI_RESPONSE_FAILED = (101, \"GenAIResponseFailed\", \"Generative AI response generation failed\")\n",
    "    # Add more error codes as needed\n",
    "\n",
    "    def __init__(self, code: int, id: str, desc: str):\n",
    "        self.code = code\n",
    "        self.id = id\n",
    "        self.desc = desc\n",
    "\n",
    "\n",
    "class BaseErrorResponse(BaseModel):\n",
    "    error_message: str\n",
    "    error_reason: str\n",
    "    error_code: int\n",
    "    error_name: str\n",
    "    technical_error_description: str | None = None  # Optional field\n",
    "\n",
    "\n",
    "class SolutionBaseException(Exception):\n",
    "\n",
    "    def __init__(self, \n",
    "                 error_message: str, \n",
    "                 error_reason: str, \n",
    "                 error_code: int, \n",
    "                 error_name: str, \n",
    "                 technical_error_description: str | None = None):\n",
    "        # Create APIErrorResponse object with the given parameters\n",
    "        self.error_response = BaseErrorResponse(\n",
    "            error_message=error_message,\n",
    "            error_reason=error_reason,\n",
    "            error_code=error_code,\n",
    "            error_name=error_name,\n",
    "            technical_error_description=technical_error_description\n",
    "        )\n",
    "        super().__init__(error_message)\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"Error Code: {self.error_response.error_code}, \"\n",
    "            f\"Error Name: {self.error_response.error_name}, \"\n",
    "            f\"Message: {self.error_response.error_message}, \"\n",
    "            f\"Reason: {self.error_response.error_reason}, \"\n",
    "            f\"Technical Description: {self.error_response.technical_error_description or 'N/A'}\"\n",
    "        )    \n",
    "\n",
    "\n",
    "\n",
    "# Define the parameterized decorator\n",
    "def log_metcustom_decorator(error: BaseErrorCodes):\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            class_name = args[0].__class__.__name__  # Get the class name\n",
    "            method_name = func.__name__  # Get the method name\n",
    "            logger.info(f\"Calling {class_name}.{method_name} with args: {args[1:]}, kwargs: {kwargs}\")\n",
    "            try:\n",
    "                result = func(*args, **kwargs)  # Call the actual method\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                raise BaseErrorResponse(\n",
    "                    error_message=error.desc,\n",
    "                    error_reason=str(e),\n",
    "                    error_code=error.code,\n",
    "                    error_name=error.id,\n",
    "                    technical_error_description=\"NA\"\n",
    "                )                \n",
    "            # logger.info(f\"{custom_message} - {class_name}.{method_name} returned: {result}\")\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class BedrockGenAIModel:\n",
    "\n",
    "    @log_metcustom_decorator(BaseErrorCodes.AWS_SESSION_FAILED)\n",
    "    def __init__(self,\n",
    "                 profile_name:str=\"bedrock-admin\"\n",
    "                 ):\n",
    "        boto3_session = boto3.session.Session(\n",
    "            profile_name = \"bedrock-admin\"\n",
    "        )\n",
    "        self.bedrock_client = boto3_session.client('bedrock-runtime')\n",
    "\n",
    "    @log_metcustom_decorator(BaseErrorCodes.GENAI_RESPONSE_FAILED)\n",
    "    def invoke_genai(   self,\n",
    "                        prompt:str,\n",
    "                        model_id:str = \"mistral.mixtral-8x7b-instruct-v0:1\",\n",
    "                        max_tokens:int = 1000, \n",
    "                        temperature:float = 0.1, \n",
    "                        top_p:float = 0.7, \n",
    "                        top_k:float = 50\n",
    "                    ):\n",
    "        self.body = json.dumps({\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k\n",
    "        })\n",
    "\n",
    "        self.response = self.bedrock_client.invoke_model(\n",
    "            body=self.body,\n",
    "            # contentType='string',\n",
    "            # accept='string',\n",
    "            modelId='mistral.mixtral-8x7b-instruct-v0:1',\n",
    "            # trace='ENABLED'|'DISABLED',\n",
    "            # guardrailIdentifier='string',\n",
    "            # guardrailVersion='string'\n",
    "        )\n",
    "\n",
    "        return self.body\n",
    "    \n",
    "\n",
    "    def response_text(self):\n",
    "        return json.loads(self.response.get('body').read())\n",
    "\n",
    "        \n",
    "\n",
    "class GenAITextGenerator:\n",
    "\n",
    "    def build_prompt(self, prompt_template:str, params:dict):\n",
    "        return prompt_template.format(**params)\n",
    "    \n",
    "\n",
    "    def __init__(self, \n",
    "                 prompt_template:str, \n",
    "                 params:dict, \n",
    "                 max_tokens:int = 1000, \n",
    "                 temperature:float = 0.1, \n",
    "                 top_p:float = 0.7, \n",
    "                 top_k:float = 50):\n",
    "        \n",
    "        self.genai_client = BedrockGenAIModel(profile_name = \"bedrock-admin\")\n",
    "        self.prompt = self.build_prompt(prompt_template, params)\n",
    "\n",
    "\n",
    "    def generate_text(self, \n",
    "                        max_tokens:int = 1000, \n",
    "                        temperature:float = 0.1, \n",
    "                        top_p:float = 0.7, \n",
    "                        top_k:float = 50\n",
    "                      ):\n",
    "\n",
    "        # logger.info(\"Generating text with Mistral AI model %s\", model_id)\n",
    "\n",
    "        # bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "        response = self.genai_client.invoke_genai(\n",
    "            prompt=self.prompt\n",
    "        )\n",
    "\n",
    "        print(response)\n",
    "\n",
    "        return self.genai_client.response_text()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Calling BedrockGenAIModel.__init__ with args: (), kwargs: {'profile_name': 'bedrock-admin'}\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:__main__:Calling BedrockGenAIModel.invoke_genai with args: (), kwargs: {'prompt': '<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \"payments\" dataset used in a travel agency. Below are the details of the columns for this dataset:\\nThe Dataset description: This table tracks payment transactions related to customer bookings. It includes details on payment methods, transaction dates, and payment amounts.\\n- attribute:payment_id attribute name:Payment ID Type:serial Description:Unique identifier for each payment transaction. This is an auto-incrementing integer that serves as the primary key.\\n- attribute:booking_id attribute name:Booking ID Type:integer Description:The identifier linking the payment to a specific booking.\\n- attribute:amount attribute name:Payment Amount Type:numeric(10, 2) Description:The amount paid in the transaction.\\n- attribute:payment_method attribute name:Payment Method Type:varchar(50) Description:The method used for payment, such as credit card, PayPal, or bank transfer.\\n- attribute:transaction_date attribute name:Transaction Date Type:timestamp Description:The date and time when the payment transaction occurred.\\n- attribute:status attribute name:Payment Status Type:varchar(50) Description:The current status of the payment, such as completed, pending, or failed.\\n- attribute:created_at attribute name:Record Created At Type:timestamp Description:Timestamp indicating when the payment record was created.\\n- attribute:updated_at attribute name:Record Updated At Type:timestamp Description:Timestamp indicating the last update to the payment record.\\n [/INST]</s>\\n[INST]Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate 5 items only and generate response in json only without any additional strings and escape sequences.[/INST]'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"prompt\": \"<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \\\"payments\\\" dataset used in a travel agency. Below are the details of the columns for this dataset:\\nThe Dataset description: This table tracks payment transactions related to customer bookings. It includes details on payment methods, transaction dates, and payment amounts.\\n- attribute:payment_id attribute name:Payment ID Type:serial Description:Unique identifier for each payment transaction. This is an auto-incrementing integer that serves as the primary key.\\n- attribute:booking_id attribute name:Booking ID Type:integer Description:The identifier linking the payment to a specific booking.\\n- attribute:amount attribute name:Payment Amount Type:numeric(10, 2) Description:The amount paid in the transaction.\\n- attribute:payment_method attribute name:Payment Method Type:varchar(50) Description:The method used for payment, such as credit card, PayPal, or bank transfer.\\n- attribute:transaction_date attribute name:Transaction Date Type:timestamp Description:The date and time when the payment transaction occurred.\\n- attribute:status attribute name:Payment Status Type:varchar(50) Description:The current status of the payment, such as completed, pending, or failed.\\n- attribute:created_at attribute name:Record Created At Type:timestamp Description:Timestamp indicating when the payment record was created.\\n- attribute:updated_at attribute name:Record Updated At Type:timestamp Description:Timestamp indicating the last update to the payment record.\\n [/INST]</s>\\n[INST]Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate 5 items only and generate response in json only without any additional strings and escape sequences.[/INST]\", \"max_tokens\": 1000, \"temperature\": 0.1, \"top_p\": 0.7, \"top_k\": 50}\n"
     ]
    }
   ],
   "source": [
    "p = {\n",
    "    \"dataset_name\":dataset_name,\n",
    "    \"dataset_description\":description,\n",
    "    \"col_prompt\":col_prompt,\n",
    "    \"items_count\":items_count,\n",
    "    \"format\":format\n",
    "}\n",
    "\n",
    "ai_message = '''<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \"{dataset_name}\" dataset used in a travel agency. Below are the details of the columns for this dataset:\n",
    "The Dataset description: {dataset_description}\n",
    "{col_prompt} [/INST]</s>\n",
    "[INST]Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. The data should mimic the distribution, range, and format as closely as possible to real-world data. Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate {items_count} items only and generate response in {format} only without any additional strings and escape sequences.[/INST]'''\n",
    "\n",
    "\n",
    "genai_res = GenAITextGenerator(prompt_template=ai_message, params=p)\n",
    "\n",
    "res = genai_res.generate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': [{'text': ' [\\n{\\n\"payment\\\\_id\": 1,\\n\"booking\\\\_id\": 12345,\\n\"amount\": 456.78,\\n\"payment\\\\_method\": \"credit card\",\\n\"transaction\\\\_date\": \"2022-03-01 14:30:00\",\\n\"status\": \"completed\",\\n\"created\\\\_at\": \"2022-03-01 14:30:00\",\\n\"updated\\\\_at\": \"2022-03-01 14:30:00\"\\n},\\n{\\n\"payment\\\\_id\": 2,\\n\"booking\\\\_id\": 23456,\\n\"amount\": 890.12,\\n\"payment\\\\_method\": \"PayPal\",\\n\"transaction\\\\_date\": \"2022-03-02 09:15:00\",\\n\"status\": \"pending\",\\n\"created\\\\_at\": \"2022-03-02 09:15:00\",\\n\"updated\\\\_at\": \"2022-03-02 09:15:00\"\\n},\\n{\\n\"payment\\\\_id\": 3,\\n\"booking\\\\_id\": 34567,\\n\"amount\": 333.00,\\n\"payment\\\\_method\": \"bank transfer\",\\n\"transaction\\\\_date\": \"2022-03-03 16:45:00\",\\n\"status\": \"completed\",\\n\"created\\\\_at\": \"2022-03-03 16:45:00\",\\n\"updated\\\\_at\": \"2022-03-03 16:45:00\"\\n},\\n{\\n\"payment\\\\_id\": 4,\\n\"booking\\\\_id\": 45678,\\n\"amount\": 111.55,\\n\"payment\\\\_method\": \"credit card\",\\n\"transaction\\\\_date\": \"2022-03-04 11:00:00\",\\n\"status\": \"failed\",\\n\"created\\\\_at\": \"2022-03-04 11:00:00\",\\n\"updated\\\\_at\": \"2022-03-04 11:00:00\"\\n},\\n{\\n\"payment\\\\_id\": 5,\\n\"booking\\\\_id\": 56789,\\n\"amount\": 777.99,\\n\"payment\\\\_method\": \"PayPal\",\\n\"transaction\\\\_date\": \"2022-03-05 18:30:00\",\\n\"status\": \"pending\",\\n\"created\\\\_at\": \"2022-03-05 18:30:00\",\\n\"updated\\\\_at\": \"2022-03-05 18:30:00\"\\n}\\n]',\n",
       "   'stop_reason': 'stop'}]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res\n",
    "# \"\\\\_sdsd\".replace(\"\\\\_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'payment_id': 1,\n",
       "  'booking_id': 12345,\n",
       "  'amount': 456.78,\n",
       "  'payment_method': 'credit card',\n",
       "  'transaction_date': '2022-03-01 14:30:00',\n",
       "  'status': 'completed',\n",
       "  'created_at': '2022-03-01 14:30:00',\n",
       "  'updated_at': '2022-03-01 14:30:00'},\n",
       " {'payment_id': 2,\n",
       "  'booking_id': 23456,\n",
       "  'amount': 890.12,\n",
       "  'payment_method': 'PayPal',\n",
       "  'transaction_date': '2022-03-02 09:15:00',\n",
       "  'status': 'pending',\n",
       "  'created_at': '2022-03-02 09:15:00',\n",
       "  'updated_at': '2022-03-02 09:15:00'},\n",
       " {'payment_id': 3,\n",
       "  'booking_id': 34567,\n",
       "  'amount': 333.0,\n",
       "  'payment_method': 'bank transfer',\n",
       "  'transaction_date': '2022-03-03 16:45:00',\n",
       "  'status': 'completed',\n",
       "  'created_at': '2022-03-03 16:45:00',\n",
       "  'updated_at': '2022-03-03 16:45:00'},\n",
       " {'payment_id': 4,\n",
       "  'booking_id': 45678,\n",
       "  'amount': 111.55,\n",
       "  'payment_method': 'credit card',\n",
       "  'transaction_date': '2022-03-04 11:00:00',\n",
       "  'status': 'failed',\n",
       "  'created_at': '2022-03-04 11:00:00',\n",
       "  'updated_at': '2022-03-04 11:00:00'},\n",
       " {'payment_id': 5,\n",
       "  'booking_id': 56789,\n",
       "  'amount': 777.99,\n",
       "  'payment_method': 'PayPal',\n",
       "  'transaction_date': '2022-03-05 18:30:00',\n",
       "  'status': 'pending',\n",
       "  'created_at': '2022-03-05 18:30:00',\n",
       "  'updated_at': '2022-03-05 18:30:00'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(res.get('outputs')[0]['text'].replace(\"\\\\_\", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \"payments\" dataset used in a travel agency. Below are the details of the columns for this dataset:\\n The Dataset description: This table tracks payment transactions related to customer bookings. It includes details on payment methods, transaction dates, and payment amounts.\\n - attribute:payment_id attribute name:Payment ID Type:serial Description:Unique identifier for each payment transaction. This is an auto-incrementing integer that serves as the primary key.\\n- attribute:booking_id attribute name:Booking ID Type:integer Description:The identifier linking the payment to a specific booking.\\n- attribute:amount attribute name:Payment Amount Type:numeric(10, 2) Description:The amount paid in the transaction.\\n- attribute:payment_method attribute name:Payment Method Type:varchar(50) Description:The method used for payment, such as credit card, PayPal, or bank transfer.\\n- attribute:transaction_date attribute name:Transaction Date Type:timestamp Description:The date and time when the payment transaction occurred.\\n- attribute:status attribute name:Payment Status Type:varchar(50) Description:The current status of the payment, such as completed, pending, or failed.\\n- attribute:created_at attribute name:Record Created At Type:timestamp Description:Timestamp indicating when the payment record was created.\\n- attribute:updated_at attribute name:Record Updated At Type:timestamp Description:Timestamp indicating the last update to the payment record.\\n [/INST]</s>\\n [INST]Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. \\n The data should mimic the distribution, range, and format as closely as possible to real-world data. \\n Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate 5 items only and generate response in json only without any additional strings and escape sequences.[/INST]\"\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"llm_config\"][\"bedrock\"][\"prompts\"][\"SYNTHETIC_DATA_GEN\"].format(**p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm_config': {'type': 'ollama',\n",
       "  'ollama': {'model': 'phi3:3.8b',\n",
       "   'temperature': 0.5,\n",
       "   'endpoint': 'http://localhost:11434'},\n",
       "  'bedrock': {'model': 'amazon.titan-tg1-large',\n",
       "   'region': 'us-east-1',\n",
       "   'prompts': {'SYNTHETIC_DATA_GEN': '\"<s>[INST] You are an AI model tasked with generating synthetic data for the Dataset: \"{dataset_name}\" dataset used in a travel agency. Below are the details of the columns for this dataset:\\n The Dataset description: {dataset_description}\\n {col_prompt} [/INST]</s>\\n [INST]Please generate a synthetic dataset in json format which would be array of key value pair, where key is the attribute and value is value, ensuring that the values conform to the descriptions and constraints provided for each column. \\n The data should mimic the distribution, range, and format as closely as possible to real-world data. \\n Ensure that referential integrity is maintained where applicable, and include a variety of values within the allowed constraints to reflect realistic data variability. Generate {items_count} items only and generate response in {format} only without any additional strings and escape sequences.[/INST]\"\\n'}},\n",
       "  'llm_api': {'endpoint': 'https://api.example.com/llm',\n",
       "   'api_key': 'your_api_key'}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'payments',\n",
       " 'dataset_description': 'This table tracks payment transactions related to customer bookings. It includes details on payment methods, transaction dates, and payment amounts.',\n",
       " 'col_prompt': '- attribute:payment_id attribute name:Payment ID Type:serial Description:Unique identifier for each payment transaction. This is an auto-incrementing integer that serves as the primary key.\\n- attribute:booking_id attribute name:Booking ID Type:integer Description:The identifier linking the payment to a specific booking.\\n- attribute:amount attribute name:Payment Amount Type:numeric(10, 2) Description:The amount paid in the transaction.\\n- attribute:payment_method attribute name:Payment Method Type:varchar(50) Description:The method used for payment, such as credit card, PayPal, or bank transfer.\\n- attribute:transaction_date attribute name:Transaction Date Type:timestamp Description:The date and time when the payment transaction occurred.\\n- attribute:status attribute name:Payment Status Type:varchar(50) Description:The current status of the payment, such as completed, pending, or failed.\\n- attribute:created_at attribute name:Record Created At Type:timestamp Description:Timestamp indicating when the payment record was created.\\n- attribute:updated_at attribute name:Record Updated At Type:timestamp Description:Timestamp indicating the last update to the payment record.\\n',\n",
       " 'items_count': 5,\n",
       " 'format': 'json'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
